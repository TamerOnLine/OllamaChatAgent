# Ollama Chat Agent ğŸš€

![Project Banner](img/screenshot.png)

![License](https://img.shields.io/badge/license-MIT-green)  
A lightweight conversational agent powered by **LangChain**, **Ollama**, and **FastAPI**. This project provides an interactive chat API using **Llama3** as the language model.

## ğŸ“ Features
- ğŸ”¥ **Conversational AI**: Uses `Llama3` for text-based interactions.
- ğŸ›  **LangChain Agent**: Implements a LangChain-powered conversational agent.
- âš¡ **FastAPI Backend**: Provides an efficient REST API for chat queries.
- ğŸ›  **Extensible Tooling**: Includes an example `echo_tool` that can be expanded.
- ğŸ–¥ **Docker-Ready**: Easily containerized for deployment.

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/TamerOnLine/tameronline-ollamachatagent.git
cd tameronline-ollamachatagent
```

### 2ï¸âƒ£ Install Dependencies
Ensure you have Python 3.9+ installed, then run:
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the FastAPI Server
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### 4ï¸âƒ£ Test the API  
Use **cURL** or **Postman** to send a chat request:

```bash
curl -X POST "http://127.0.0.1:8000/chat/" -H "Content-Type: application/json" -d '{"query": "Hello, how are you?"}'
```

Expected JSON response:
```json
{
    "response": "Hello! How can I assist you today?"
}
```

---

## ğŸ›  Project Structure
```
tameronline-ollamachatagent/
â”‚â”€â”€ agent.py              # Defines the LangChain Agent with Llama3
â”‚â”€â”€ main.py               # FastAPI server handling chat requests
â”‚â”€â”€ requirements.txt      # Dependencies list
â”‚â”€â”€ LICENSE               # MIT License
â”‚â”€â”€ README.md             # Project Documentation
â””â”€â”€ img/                  # Images or assets (if any)
```

---

## âš¡ Configuration
By default, the model used is **Llama3**. If you want to switch to another Ollama model (e.g., `mistral`), modify `agent.py`:
```python
llm = ChatOllama(model="mistral", temperature=0)
```

---

## ğŸ›  Extending the Agent
### Adding Custom Tools
You can extend the agent by defining new tools. Example:
```python
def reverse_tool(text: str):
    return text[::-1]  # Reverses the input text

tools.append(Tool(name="reverse_tool", func=reverse_tool, description="Reverses the input text."))
```

---

## ğŸ³ Docker Support
To run this project in a container:
```bash
docker build -t ollama-chat-agent .
docker run -p 8000:8000 ollama-chat-agent
```

---

## ğŸ“œ License
This project is licensed under the **MIT License**. See [LICENSE](LICENSE) for details.

---

## ğŸ“© Contact
- **Author:** [Tamer Hamad Faour](https://www.linkedin.com/in/tameronline/)
- **GitHub:** [TamerOnLine](https://github.com/TamerOnLine)
- **Website:** [mystrotamer.com](https://www.tameronline.com/)

---

ğŸŒŸ **Enjoy building with Ollama & LangChain!** ğŸš€

